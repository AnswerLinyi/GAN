{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Deep Convolutional Generative Adverserial Networks（DCGAN）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: imageio in d:\\anaconda\\lib\\site-packages (2.3.0)\n"
     ]
    }
   ],
   "source": [
    "# 生成 gifs\n",
    "!pip install imageio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 导入Tensorflow 以及 enable eagerExecution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "from __future__ import  absolute_import,division,print_function\n",
    "\n",
    "import tensorflow as tf\n",
    "import os\n",
    "import numpy as np\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "import PIL\n",
    "import imageio\n",
    "from IPython import display\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.10.0'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.enable_eager_execution()\n",
    "tf.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 加载数据"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "我们将使用MNIST数据集来训练生成器器和鉴别器。 然后，生成器将生成手写数字。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "(train_images,train_labels),(_,_) = tf.keras.datasets.mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images = train_images.reshape(train_images.shape[0], 28, 28, 1).astype('float32')\n",
    "# We are normalizing the images to the range of [-1, 1]\n",
    "train_images = (train_images - 127.5) / 127.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "BUFFER_SIZE = 60000\n",
    "BATCH_SIZE = 256"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 打乱数据生成batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = tf.data.Dataset.from_tensor_slices(train_images).shuffle(BUFFER_SIZE).batch(BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 生成器和鉴别器模型"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "生成器：\n",
    "它负责创造令人信服的图像，足以愚弄鉴别器。它由Conv2DTranspose（Upsampling）层组成。我们从完全连接的层开始，并对图像进行2次上采·样，以便达到所需的图像尺寸（mnist图像尺寸），即（28,28,1）。出去最后一层我们使用tanh激活函数，其余各层我们采用leaky relu激活函数进行激活。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generator(tf.keras.Model):\n",
    "  def __init__(self):\n",
    "    super(Generator, self).__init__()\n",
    "    self.fc1 = tf.keras.layers.Dense(7*7*64, use_bias=False)\n",
    "    self.batchnorm1 = tf.keras.layers.BatchNormalization()\n",
    "    \n",
    "    self.conv1 = tf.keras.layers.Conv2DTranspose(64, (5, 5), strides=(1, 1), padding='same', use_bias=False)\n",
    "    self.batchnorm2 = tf.keras.layers.BatchNormalization()\n",
    "    \n",
    "    self.conv2 = tf.keras.layers.Conv2DTranspose(32, (5, 5), strides=(2, 2), padding='same', use_bias=False)\n",
    "    self.batchnorm3 = tf.keras.layers.BatchNormalization()\n",
    "    \n",
    "    self.conv3 = tf.keras.layers.Conv2DTranspose(1, (5, 5), strides=(2, 2), padding='same', use_bias=False)\n",
    "\n",
    "  def call(self, x, training=True):\n",
    "    x = self.fc1(x)\n",
    "    x = self.batchnorm1(x, training=training)\n",
    "    x = tf.nn.relu(x)\n",
    "\n",
    "    x = tf.reshape(x, shape=(-1, 7, 7, 64))\n",
    "\n",
    "    x = self.conv1(x)\n",
    "    x = self.batchnorm2(x, training=training)\n",
    "    x = tf.nn.relu(x)\n",
    "\n",
    "    x = self.conv2(x)\n",
    "    x = self.batchnorm3(x, training=training)\n",
    "    x = tf.nn.relu(x)\n",
    "\n",
    "    x = tf.nn.tanh(self.conv3(x))  \n",
    "    return x"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "\n",
    "鉴别器：\n",
    "鉴别器负责对来自真实图像的伪图像进行分类。换句话说，鉴别器获取的生成的图像（来自生成器）和真实的MNIST图像。 鉴别器的工作是将这些图像分类为伪（生成）和真实（MNIST图像）。基本上，生成器应该足以欺骗鉴别器。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class Discriminator(tf.keras.Model):\n",
    "  def __init__(self):\n",
    "    super(Discriminator, self).__init__()\n",
    "    self.conv1 = tf.keras.layers.Conv2D(64, (5, 5), strides=(2, 2), padding='same')\n",
    "    self.conv2 = tf.keras.layers.Conv2D(128, (5, 5), strides=(2, 2), padding='same')\n",
    "    self.dropout = tf.keras.layers.Dropout(0.3)\n",
    "    self.flatten = tf.keras.layers.Flatten()\n",
    "    self.fc1 = tf.keras.layers.Dense(1)\n",
    "\n",
    "  def call(self, x, training=True):\n",
    "    x = tf.nn.leaky_relu(self.conv1(x))\n",
    "    x = self.dropout(x, training=training)\n",
    "    x = tf.nn.leaky_relu(self.conv2(x))\n",
    "    x = self.dropout(x, training=training)\n",
    "    x = self.flatten(x)\n",
    "    x = self.fc1(x)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator = Generator()\n",
    "discriminator = Discriminator()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "在使用eager execution时，可以通过tf.contrib.eager.defun对代码的某些部分使用图执行。这要求你使用TensorFlow图形操作，如tf.cond（）。 将来，AutoGraph将与defun无缝集成，以允许在简单的eager 风格的Python中创作图形代码。 当该实现可用时，你可以通过选择性地将eager代码转换为graph fragments来使用AutoGraph加速热点。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator.call = tf.contrib.eager.defun(generator.call)\n",
    "discriminator.call = tf.contrib.eager.defun(discriminator.call)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 定义损失函数和optimizer"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "鉴别器的损失：\n",
    "鉴别器损失函数需要2个输入; 真实图像，生成图像，real_loss是真实图像的sigmoid交叉熵损失和一个单位数组（因为这些是真实的图像），generated_loss是生成的图像的sigmoid交叉熵损失和单位数组（因为这些是伪图像），total_loss是real_loss和generated_loss之和。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def discriminator_loss(real_output, generated_output):\n",
    "    # [1,1,...,1] with real output since it is true and we want\n",
    "    # our generated examples to look like it\n",
    "    real_loss = tf.losses.sigmoid_cross_entropy(multi_class_labels=tf.ones_like(real_output), logits=real_output)\n",
    "\n",
    "    # [0,0,...,0] with generated images since they are fake\n",
    "    generated_loss = tf.losses.sigmoid_cross_entropy(multi_class_labels=tf.zeros_like(generated_output), logits=generated_output)\n",
    "\n",
    "    total_loss = real_loss + generated_loss\n",
    "\n",
    "    return total_loss"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "生成器的损失:\n",
    "它是生成的图像的sigmoid交叉熵损失和一组单位数组"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generator_loss(generated_output):\n",
    "    return tf.losses.sigmoid_cross_entropy(tf.ones_like(generated_output), generated_output)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "鉴别器和生成器优化器是不同的，因为将分别训练它们。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "discriminator_optimizer = tf.train.AdamOptimizer(1e-4)\n",
    "generator_optimizer = tf.train.AdamOptimizer(1e-4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Checkpoints(Object-based saving)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "对可检查对象进行分组，保存并恢复它们。\n",
    "\n",
    "Checkpoint的构造函数接受关键字参数，其值是包含checkpointable状态的类型，例如tf.train.Optimizer 实现tf.Variable，tf.keras.Layer实现或 tf.keras.Model实现。它使用检查点保存这些值，并维护save_counter编号检查点。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_dir = './training_checkpoints'\n",
    "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt\")\n",
    "checkpoint = tf.train.Checkpoint(generator_optimizer=generator_optimizer,\n",
    "                                 discriminator_optimizer=discriminator_optimizer,\n",
    "                                 generator=generator,\n",
    "                                 discriminator=discriminator)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 训练"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "我们首先迭代数据集，然后将赋予噪声的生成器作为输入，当通过生成器模型时将输出看起来像手写数字的图像，而鉴别器被给予真实的MNIST图像以及生成的图像（来自发生器）。接下来，我们计算和鉴别器损失。然后，我们计算相对于生成器和鉴别器变量（输入）的损耗梯度，并将它们应用于优化器。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 1\n",
    "noise_dim = 100\n",
    "num_examples_to_generate = 16\n",
    "\n",
    "# keeping the random vector constant for generation (prediction) so\n",
    "# it will be easier to see the improvement of the gan.\n",
    "random_vector_for_generation = tf.random_normal([num_examples_to_generate,\n",
    "                                                 noise_dim])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_and_save_images(model, epoch, test_input):\n",
    "  # make sure the training parameter is set to False because we\n",
    "  # don't want to train the batchnorm layer when doing inference.\n",
    "  predictions = model(test_input, training=False)\n",
    "\n",
    "  fig = plt.figure(figsize=(4,4))\n",
    "  \n",
    "  for i in range(predictions.shape[0]):\n",
    "      plt.subplot(4, 4, i+1)\n",
    "      plt.imshow(predictions[i, :, :, 0] * 127.5 + 127.5, cmap='gray')\n",
    "      plt.axis('off')\n",
    "        \n",
    "  plt.savefig('image_at_epoch_{:04d}.png'.format(epoch))\n",
    "  plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(dataset, epochs, noise_dim):  \n",
    "  for epoch in range(epochs):\n",
    "    start = time.time()\n",
    "    \n",
    "    for images in dataset:\n",
    "      # generating noise from a uniform distribution\n",
    "      noise = tf.random_normal([BATCH_SIZE, noise_dim])\n",
    "      \n",
    "      with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape:\n",
    "        generated_images = generator(noise, training=True)\n",
    "      \n",
    "        real_output = discriminator(images, training=True)\n",
    "        generated_output = discriminator(generated_images, training=True)\n",
    "        \n",
    "        gen_loss = generator_loss(generated_output)\n",
    "        disc_loss = discriminator_loss(real_output, generated_output)\n",
    "        \n",
    "      gradients_of_generator = gen_tape.gradient(gen_loss, generator.variables)\n",
    "      gradients_of_discriminator = disc_tape.gradient(disc_loss, discriminator.variables)\n",
    "      \n",
    "      generator_optimizer.apply_gradients(zip(gradients_of_generator, generator.variables))\n",
    "      discriminator_optimizer.apply_gradients(zip(gradients_of_discriminator, discriminator.variables))\n",
    "\n",
    "      \n",
    "    if epoch % 1 == 0:\n",
    "      display.clear_output(wait=True)\n",
    "      generate_and_save_images(generator,\n",
    "                               epoch + 1,\n",
    "                               random_vector_for_generation)\n",
    "    \n",
    "    # saving (checkpoint) the model every 15 epochs\n",
    "    if (epoch + 1) % 1 == 0:\n",
    "      checkpoint.save(file_prefix = checkpoint_prefix)\n",
    "    \n",
    "    print ('Time taken for epoch {} is {} sec'.format(epoch + 1,\n",
    "                                                      time.time()-start))\n",
    "  # generating after the final epoch\n",
    "  display.clear_output(wait=True)\n",
    "  generate_and_save_images(generator,\n",
    "                           epochs,\n",
    "                           random_vector_for_generation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train(train_dataset, EPOCHS, noise_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
