{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.10.0'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting /MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting /MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting /MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting /MNIST_data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets('/MNIST_data/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label: 0\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "i = 10\n",
    "img = mnist.train.images[i]\n",
    "plt.imshow(img.reshape(28,28),cmap='Greys_r')\n",
    "print(\"Label: {}\".format(mnist.train.labels[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_inputs(noise_dim,image_height,image_width,image_depth):\n",
    "    \"\"\"\n",
    "    --------------------\n",
    "    :param noise_dim: 噪声图片的size\n",
    "    :param image_height: 真实图像的height\n",
    "    :param image_width: 真实图像的width\n",
    "    :param image_depth: 真实图像的depth\n",
    "    \"\"\" \n",
    "    \n",
    "    inputs_real = tf.placeholder(tf.float32,[None,image_width,image_height,image_depth])\n",
    "    inputs_nosie = tf.placeholder(tf.float32,[None,noise_dim],name='inputs_noise')\n",
    "    \n",
    "    return inputs_real,inputs_nosie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_generator(noise_img, output_dim, is_train=True):\n",
    "    \"\"\"\n",
    "    --------------------\n",
    "    :param noise_img: 噪声信号，tensor类型\n",
    "    :param output_dim: 生成图片的depth\n",
    "    :param is_train: 是否为训练状态，该参数主要用于作为batch_normalization方法中的参数使用\n",
    "    \"\"\"\n",
    "    \n",
    "    with tf.variable_scope(\"generator\", reuse=(not is_train)):\n",
    "        # 100 x 1 to 4 x 4 x 512\n",
    "        # 全连接层\n",
    "        layer1 = tf.layers.dense(noise_img, 4*4*512)\n",
    "        layer1 = tf.reshape(layer1, [-1, 4, 4, 512])\n",
    "        #batch normalization\n",
    "        layer1 = tf.layers.batch_normalization(layer1,training=is_train)\n",
    "        #Leaky ReLu\n",
    "        layer1 = tf.nn.leaky_relu(layer1,alpha=0.01)\n",
    "        #dropout\n",
    "        layer1 = tf.nn.dropout(layer1,keep_prob=0.8)\n",
    "        \n",
    "        # 4 x 4 x 512 to 7 x 7 x 256\n",
    "        layer2 = tf.layers.conv2d_transpose(layer1,256,4,strides=1,padding='valid')\n",
    "        layer2 = tf.layers.batch_normalization(layer2,training=is_train)\n",
    "        layer2 = tf.nn.leaky_relu(layer2,alpha=0.01)\n",
    "        layer2 = tf.nn.dropout(layer2,keep_prob=0.8)\n",
    "        \n",
    "        ## 7 x 7 256 to 14 x 14 x 128\n",
    "        layer3 = tf.layers.conv2d_transpose(layer2,128,3,strides=2,padding='same')\n",
    "        layer3 = tf.layers.batch_normalization(layer3,training=is_train)\n",
    "        layer3 = tf.nn.leaky_relu(layer3,alpha=0.01)\n",
    "        layer3 = tf.nn.dropout(layer3,keep_prob=0.8)\n",
    "        \n",
    "        # 14 x 14 x 128 to 28 x 28 x 1\n",
    "        logits = tf.layers.conv2d_transpose(layer3,output_dim,3,strides=2,padding='same')\n",
    "        \n",
    "        # MNIST原始数据集的像素范围在0-1，这里的生成图片范围为(-1,1)\n",
    "        # 因此在训练时，记住要把MNIST像素范围进行resize\n",
    "        outputs = tf.tanh(logits)\n",
    "        \n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_discriminator(input_img,reuse=False):\n",
    "    \"\"\"\n",
    "    --------------------\n",
    "    @param inputs_img: 输入图片，tensor类型\n",
    "    \"\"\"\n",
    "    with tf.variable_scope(\"discriminator\",reuse=reuse):\n",
    "        # 28 x 28 x 1 to 14 x 14 x 128\n",
    "        # 第一层不加入BN\n",
    "        layer1 = tf.layers.conv2d(input_img,128,3,strides=2,padding='same')\n",
    "        layer1 = tf.nn.leaky_relu(layer1,alpha=0.01)\n",
    "        layer1 = tf.nn.dropout(layer1,keep_prob=0.8)\n",
    "        \n",
    "        # 14 x 14 x 128 to 7 x 7 x 256\n",
    "        layer2 = tf.layers.conv2d(layer1,256,3,strides=3,padding='same')\n",
    "        layer2 = tf.layers.batch_normalization(layer2,training=True)\n",
    "        layer2 = tf.nn.leaky_relu(layer2,alpha=0.01)\n",
    "        layer2 = tf.nn.dropout(layer2,keep_prob=0.8)\n",
    "        \n",
    "        # 7 x 7 x 256 to 4 x 4 x 512\n",
    "        layer3 = tf.layers.conv2d(layer2,512,3,strides=2,padding='same')\n",
    "        layer3 = tf.layers.batch_normalization(layer3,training=True)\n",
    "        layer3 = tf.nn.leaky_relu(layer3,alpha=0.01)\n",
    "        layer3 = tf.nn.dropout(layer3,keep_prob=0.8)\n",
    "        \n",
    "        # 4 x 4 x 512 to 4*4*512 x 1\n",
    "        flatten = tf.reshape(layer3,(-1,4*4*512))\n",
    "        logits = tf.layers.dense(flatten,1)\n",
    "        outputs = tf.sigmoid(logits)\n",
    "        \n",
    "        return logits,outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_loss(inputs_real,inputs_noise,image_depth,smooth=0.1):\n",
    "    \"\"\"\n",
    "    --------------------\n",
    "    @param inputs_real: 输入图片，tensor类型\n",
    "    @param inputs_noise: 噪声图片，tensor类型\n",
    "    @param image_depth: 图片的depth（或者叫channel）\n",
    "    @param smooth: label smoothing的参数\n",
    "    \"\"\"\n",
    "    \n",
    "    g_outputs = get_generator(inputs_noise,image_depth,is_train=True)\n",
    "    d_logits_real,d_outputs_real = get_discriminator(inputs_real)\n",
    "    d_logits_fake,d_outputs_fake = get_discriminator(g_outputs,reuse=True)\n",
    "    \n",
    "    #计算Loss \n",
    "    g_loss = tf.reduce_mean(\n",
    "        tf.nn.sigmoid_cross_entropy_with_logits(\n",
    "            logits=d_logits_fake,\n",
    "            labels=tf.ones_like(d_outputs_fake)*(1-smooth)\n",
    "        )\n",
    "    )\n",
    "    \n",
    "    d_loss_real =tf.reduce_mean(\n",
    "        tf.nn.sigmoid_cross_entropy_with_logits(\n",
    "            logits=d_logits_real,\n",
    "            labels=tf.ones_like(d_outputs_real)*(1-smooth)\n",
    "        )\n",
    "    )\n",
    "    \n",
    "    d_loss_fake = tf.reduce_mean(\n",
    "        tf.nn.sigmoid_cross_entropy_with_logits(\n",
    "           logits = d_logits_fake,\n",
    "           labels = tf.zeros_like(d_outputs_real)\n",
    "        )   \n",
    "    )\n",
    "    \n",
    "    d_loss = tf.add(d_loss_real,d_loss_fake)\n",
    "    \n",
    "    return g_loss,d_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_optimizer(g_loss, d_loss, beta1=0.4, learning_rate=0.001):\n",
    "    \"\"\"\n",
    "    @Author: Nelson Zhao\n",
    "    --------------------\n",
    "    @param g_loss: Generator的Loss\n",
    "    @param d_loss: Discriminator的Loss\n",
    "    @learning_rate: 学习率\n",
    "    \"\"\"\n",
    "    \n",
    "    train_vars = tf.trainable_variables()\n",
    "    \n",
    "    g_vars = [var for var in train_vars if var.name.startswith(\"generator\")]\n",
    "    d_vars = [var for var in train_vars if var.name.startswith(\"discriminator\")]\n",
    "    \n",
    "    # Optimizer\n",
    "    with tf.control_dependencies(tf.get_collection(tf.GraphKeys.UPDATE_OPS)):\n",
    "        g_opt = tf.train.AdamOptimizer(learning_rate, beta1=beta1).minimize(g_loss, var_list=g_vars)\n",
    "        d_opt = tf.train.AdamOptimizer(learning_rate, beta1=beta1).minimize(d_loss, var_list=d_vars)\n",
    "    \n",
    "    return g_opt, d_opt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_images(samples):\n",
    "    fig, axes = plt.subplots(nrows=1, ncols=25, sharex=True, sharey=True, figsize=(50,2))\n",
    "    for img, ax in zip(samples, axes):\n",
    "        ax.imshow(img.reshape((28, 28)), cmap='Greys_r')\n",
    "        ax.get_xaxis().set_visible(False)\n",
    "        ax.get_yaxis().set_visible(False)\n",
    "    fig.tight_layout(pad=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_generator_output(sess, n_images, inputs_noise, output_dim):\n",
    "    \"\"\"\n",
    "    @Author: Nelson Zhao\n",
    "    --------------------\n",
    "    @param sess: TensorFlow session\n",
    "    @param n_images: 展示图片的数量\n",
    "    @param inputs_noise: 噪声图片\n",
    "    @param output_dim: 图片的depth（或者叫channel）\n",
    "    @param image_mode: 图像模式：RGB或者灰度\n",
    "    \"\"\"\n",
    "    cmap = 'Greys_r'\n",
    "    noise_shape = inputs_noise.get_shape().as_list()[-1]\n",
    "    # 生成噪声图片\n",
    "    examples_noise = np.random.uniform(-1, 1, size=[n_images, noise_shape])\n",
    "\n",
    "    samples = sess.run(get_generator(inputs_noise, output_dim, False),\n",
    "                       feed_dict={inputs_noise: examples_noise})\n",
    "\n",
    "    \n",
    "    result = np.squeeze(samples, -1)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义参数\n",
    "batch_size = 64\n",
    "noise_size = 100\n",
    "epochs = 5\n",
    "n_samples = 25\n",
    "learning_rate = 0.001\n",
    "beta1 = 0.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(noise_size, data_shape, batch_size, n_samples):\n",
    "    \"\"\"\n",
    "    @Author: Nelson Zhao\n",
    "    --------------------\n",
    "    @param noise_size: 噪声size\n",
    "    @param data_shape: 真实图像shape\n",
    "    @batch_size:\n",
    "    @n_samples: 显示示例图片数量\n",
    "    \"\"\"\n",
    "    \n",
    "    # 存储loss\n",
    "    losses = []\n",
    "    steps = 0\n",
    "    \n",
    "    inputs_real, inputs_noise = get_inputs(noise_size, data_shape[1], data_shape[2], data_shape[3])\n",
    "    g_loss, d_loss = get_loss(inputs_real, inputs_noise, data_shape[-1])\n",
    "    g_train_opt, d_train_opt = get_optimizer(g_loss, d_loss, beta1, learning_rate)\n",
    "\n",
    "    with tf.Session() as sess:\n",
    "        sess.run(tf.global_variables_initializer())\n",
    "        # 迭代epoch\n",
    "        for e in range(epochs):\n",
    "            for batch_i in range(mnist.train.num_examples//batch_size):\n",
    "                steps += 1\n",
    "                batch = mnist.train.next_batch(batch_size)\n",
    "\n",
    "                batch_images = batch[0].reshape((batch_size, data_shape[1], data_shape[2], data_shape[3]))\n",
    "                # scale to -1, 1\n",
    "                batch_images = batch_images * 2 - 1\n",
    "\n",
    "                # noise\n",
    "                batch_noise = np.random.uniform(-1, 1, size=(batch_size, noise_size))\n",
    "\n",
    "                # run optimizer\n",
    "                _ = sess.run(g_train_opt, feed_dict={inputs_real: batch_images,\n",
    "                                                     inputs_noise: batch_noise})\n",
    "                _ = sess.run(d_train_opt, feed_dict={inputs_real: batch_images,\n",
    "                                                     inputs_noise: batch_noise})\n",
    "                \n",
    "                if steps % 101 == 0:\n",
    "                    train_loss_d = d_loss.eval({inputs_real: batch_images,\n",
    "                                                inputs_noise: batch_noise})\n",
    "                    train_loss_g = g_loss.eval({inputs_real: batch_images,\n",
    "                                                inputs_noise: batch_noise})\n",
    "                    losses.append((train_loss_d, train_loss_g))\n",
    "                    # 显示图片\n",
    "                    samples = show_generator_output(sess, n_samples, inputs_noise, data_shape[-1])\n",
    "                    plot_images(samples)\n",
    "                    print(\"Epoch {}/{}....\".format(e+1, epochs), \n",
    "                          \"Discriminator Loss: {:.4f}....\".format(train_loss_d),\n",
    "                          \"Generator Loss: {:.4f}....\". format(train_loss_g))\n",
    "                                   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.Graph().as_default():\n",
    "    train(noise_size, [-1, 28, 28, 1], batch_size, n_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
